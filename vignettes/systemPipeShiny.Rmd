---
title: "systemPipeShiny" 
author: "Author: Le Zhang, Daniela Cassol, Ponmathi Ramasamy, Jianhai Zhang, Gordon Mosher, Thomas Girke"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`" 
output:
  BiocStyle::html_document:
    toc_float: true
    code_folding: show
  BiocStyle::pdf_document: default
package: systemPipeR
vignette: |
  %\VignetteIndexEntry{systemPipeShiny}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
fontsize: 14pt
bibliography: bibtex.bib
---

```{css, echo=FALSE, eval=FALSE}
pre code {
white-space: pre !important;
overflow-x: scroll !important;
word-break: keep-all !important;
word-wrap: initial !important;
}
```

```{r style, echo = FALSE, results = 'asis', eval=FALSE}
BiocStyle::markdown()
options(width=60, max.print=1000)
knitr::opts_chunk$set(
    eval=as.logical(Sys.getenv("KNITR_EVAL", "TRUE")),
    cache=as.logical(Sys.getenv("KNITR_CACHE", "TRUE")), 
    tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

```{r setup, echo=FALSE, messages=FALSE, warnings=FALSE, eval=TRUE}
suppressPackageStartupMessages({
    library(systemPipeR)
    library(systemPipeShiny)
})
```

# Introduction

Accelerate data analysis with interactive systemPipeShiny toolkits

![systemPipeShiny](./systemPipeShiny.png)

- [Image Link edition](https://drive.google.com/file/d/1kRG_QGbB0w3tgQh17hJtFqXrF5gwI9Tv/view?usp=sharing)

TODO: 
Describe the package
Motivation 


## Features

### systemPipeShiny: Shiny Web Interface
Shiny application for interactive workflow management and results visualization generated by *systemPipeR*

- Interactive workflow management
  - Create metadata from new or templates; 
  - checkers to help users validate target file (names, file existence, statistics)

- Visualize workflow structure, choose steps 
   - Interactive data visualization
   - Plots of downstream analysis, like DEG, GO and other plots used in some specific workflows, like Venn diagram, dendrogram


## Quick start

```{r, eval=FALSE}
library(systemPipeShiny)
spsInit()
```

Then there should be a project folder created for you. By default, it is named `SPS_`+`DATE`. 
Your working directory should be set inside that project folder automatically. 
If you are using Rstudio, three main files will be opened for you: `global.R`, `ui.R` and `server.R`. 
Now you can just run the app by type `shiny::runApp()` in console or click on the green `> Run App` 
button on top right corner of the any these 3 files in Rstudio. 
In your global.R, scroll down to the bottom, you should see:


```{r, eval=FALSE}
sps_app <- sps(
    vstabs = "",
    server_expr = {
        msg("Custom expression runs -- Hello World", "GREETING", "green")
    }
)
```

This is the SPS main function. You can load/unload tabs by providing tab IDs in `vstabs` argument, like 
`c("tab1", "tab2)`. See `config/tabs.csv` in your project folder for what tabs IDs can be load and other 
tab information. 

# Install

```{r, eval=FALSE}
if (!requireNamespace("BiocManager", quietly=TRUE))
    install.packages("BiocManager")
BiocManager::install("systemPipeR/systemPipeShiny", build_vignettes=TRUE, dependencies=TRUE)
```

If you are on Linux, you also need:

```{bash, eval=FALSE}
# use ubuntu as example
sudo apt-get install libv8-dev
sudo apt-get install libssl-dev
sudo apt-get install libcurl4-openssl-dev
```
*libcurl4-openssl-dev* may not be required for Ubuntu >= 18.04

# Setting up the data

# Launching the application

# Description of the user interface
## dashboard
## layout 
## each tab
## Workflow Management system
# Description of *systemPipeShiny* functionality
# SPS configurations
## the config folder
## SPS options
## SPS tab
## SPS database
# For developers
## Tab control
### Tab classification
### New data tab
### New plot tab
### Load new tab to the framework
### Remove a tab
### a Empty tab for advanced devleopers
## 


## Visualization 

*systemPipeShiny* offers interactive data visualization to users and supports graphics in workflow reports. In systemPipeShiny's visualization tab, there are many features for data visualization of various statistical results. Users can upload different input data types, and apply various options for preprocessing those datasets. Users can then create downstream analysis plots, as per the type of uploaded data. Some available plotting options include: bar plots of differentially expressed genes, heat maps, dendrogram, principal component analysis (PCA) plots, and multidimensional scaling (MDS) plots. Depending on the nature of the plots, there are also options to adjust the plot such as normalizing the data. Additionally, systemPipeShiny provides users with plot templates and plotting functions that they can then customize according to their necessities for visualization.

Table with all exported functions

| Function Name   | Description                                                     |
|-----------------|-----------------------------------------------------------------|
| `exploreDSS`    | transform raw read counts using the \code{DESeq2} package       |
| `plotExploreDSS`| Scatterplot of transformed counts from two samples              |
| `plotPCA_sps`   | Plots PCA from a count matrix                                   |
| `plotMDS`       | Plots MDS from a count matrix                                   |
| `plotTSNE`      | Plots t-SNE from a count matrix                                 |
| `plotGLM`       | Plots GLM-PCA from a count matrix                               |
| `plotHeatMap`   | Plots Heatmap from a count matrix                               |
| `plot_MA`       | Plots a clustering dendrogram from a count matrix               |
| `run_volcano`   | Plots a Volcano Plot from an edgeR or deseq2 dataframe          |
| `deg_edgeR`     | Plots barplot of DEGs from a count matrix, returns an edgeR DF  |
| `deg_deseq2`    | Plots barplot of DEGs from a count matrix, returns an deseq2 DF |

### Data transformations and visualization

To show the effect of the transformation, in the figure below we plot the first sample against the second, first simply using the `log2` function, and then using the `VST` and `rlog-transformed` values. For the log2 approach, we need to first estimate size factors to account for sequencing depth, and then specify `normalized=TRUE`. Sequencing depth correction is done automatically for the `vst` and `rlog.`

```{r, eval=TRUE}
targetspath <- system.file("extdata", "targets.txt", package="systemPipeR")
targets <- read.delim(targetspath, comment="#")
cmp <- systemPipeR::readComp(file=targetspath, format="matrix", delim="-")
countMatrixPath <- system.file("extdata", "countDFeByg.xls", package="systemPipeR")
countMatrix <- read.delim(countMatrixPath, row.names=1)
plotExploreDSS(countMatrix, targets, cmp = cmp[[1]], preFilter = 10, sample = c(3,4))
```

## Barplot

A barplot for analysis of differentially expressed genes (DEGs) can be plotted using functions `deg_edgeR` or `deg_deseq2`. The function `deg_edgeR` uses the `edgeR` package [@Robinson2010-uk] to create an `edgeR` data frame. Alternatively, the function `deg_deseq2` uses the `DESeq2` package [@Love2014-sh] to create an `DESeq2` data frame. Using the `filterDEGs` function, it filters and plots DEG results for up and down regulated genes in a barplot. 

## Heatmap

A heatmap of the results of hierarchical clustering performed with the `hclust` function can be created with the `run_HEAT` function. The sample-wise Spearman correlation coefficients are computed before hierarchical clustering. The count data frame can be transformed with the `rlog` or Variance-stabilizing Transformation (`vst`) methods from the `DESeq2` package, or can be done without transformation. 

## Dendrogram

A dendrogram of the results of hierarchical clustering performed with the `hclust` function can be created with the `run_CLUST` function. The sample-wise Spearman correlation coefficients are computed, and then the results are transformed to a distance matrix before the hierarchical clustering is performed. The count data frame can be transformed with the `rlog` or Variance-stabilizing Transformation (`vst`) methods from the `DESeq2` package, or can be done without transformation. 

## t-SNE plot

A Barnes-Hut t-Distributed Stochastic Neighbor Embedding (t-SNE) plot can be created using the `run_TSNE` function, which uses the `Rtsne` package [@Krijthe2015] to compute t-SNE values. The function removes duplicates in the input data frame, sets a seed for reproducility, performs an initial PCA step. The function also allows for a user-set perplexity value for the computation. 

## PCA plot

A Principal Component Analysis (PCA) plot can be created using the `run_PCA` function which uses the `DESeq2` package. The input data frame can be transformed with the `rlog` or Variance-stabilizing Transformation (`vst`) methods from the `DESeq2` package, or can be done without transformation. 
In addition, generalized principal component analysis (GLM-PCA) for dimension reduction of non-normally distributed data can be plotted with the `run_GLM` function [@Townes2019]. This option does not offer transformation or normalization of raw data.

## MDS plot

A Multidimensional Scaling (MDS) plot can be created using the `run_MDS` function.  The input data frame can be transformed with either the `rlog` or Variance-stabilizing Transformation (`vst`) methods from the `DESeq2` package. From the input data, it computes a spearman correlation-based distance matrix and performs MDS analysis on it.

## Volcano plot

A volcano plot of DEGs data frame can be plotted using the function `run_volcano`. Using the resulting data frame from `run_edgeR` or `run_deseq2`, the function plots a volcano plot using False Discovery Rate and Log Fold Change thresholds for the sample comparison specified by the user.

# How to use this function on the Shiny application

# How to custom the Visualization Tab

# For developers
  
## Coventions for this app

### 1. App structure
1. Directories:
    1. config: config files
    2. data: example datasets 
    3. results: not in use for now but users can store data generated from the app
    3. R: all functions, tabs. This folder will be automatically sourced
    4. www: html web resources, will be treated as root of frontend resources
    
Each folder has a README.md. You can know more information by reading that file. 

### 2. Important files    
1. Three big files in the main directory:
    - **global.R**: all sourcing, load library, global variables.
    - **server.R**: top level server function, automatically generated by `sps()`.
    - **ui.R**: top level UI, automatically generated by `sps()`.

All you need is to change code in `global`

### 3. Naming
1. tabs:
    - All store in `R` folder;
    - All should be named as `tab_xx.R`; if a submodule contains submodule. If 
    this tab is a sub tab, name it `tab_type_id.R`, e.g. a tab for 
    visualization new data type will be `tab_vs_data_xxx.R`, a new plot tab will be 
    `tab_vs_plot_xxx.R`.
    - All tab info should also be updated in `tabs.csv` as the tab metadata.
        - visualization data tabs should hava tab name as `data_xx`, plot tab 
        should be `plot_xx`
    
2. functions:
    - in each *tab* file, there should be one `UI` function and one `server` 
    function and give both functions and name space the same ID as the file name: 
    e.g. a file named `tab_sub1.R`, UI function will be `sub1UI`, server will be 
    `sub1Server` and in top level UI and server call them `sub1UI("sub1", ...)`, 
    `callModule(tab1Server, "tab1", ...)`.

## 4. Standard for visualization
1. Plots
    - In princple, datasets should be plotting ready (no need to preprocess data). 
    - For some plots that are very specific to some workflows, simple preprocess is okay.
    - Always use a button to update (re-plot) the graph, realtime rendering can be expensive. 

## 5. Objects saved in `shared`

"Shared" is first defined in the top level server as a shiny `ReactiveValues` object to hold data that can
be passed around tabs(modules). This is very important if you want to transfer like a 
dataframe from df tabs to plotting tabs. 

To access values in `shared`, use `$` or `[['name']]`, e.g. `shared$xxx$subxxx` or `shared[['xxx']][['subxxx']]`.

### default stored objects

- wf_flags: bool values to indicate required files status for the workflow
    - targets_ready, wf_ready, wf_conf_ready: target file, workflow Rmd file, config yaml file
    
- targets: targets file
    - df: dataframe, which will be used to display from top push bar
    - file: string, the temp path of edited targets. When `add to task` is clicked and 
    check passed, this file will be write to temp with **target header**
    
- count: count table
    - df, file: same as targets
    
- config: configuration yaml file
    - file: same as targets

# How to deploy the application

# Version Information

```{r sessionInfo, eval=TRUE}
sessionInfo()
```

# Funding

# References
